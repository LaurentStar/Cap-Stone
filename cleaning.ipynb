{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data process\n",
    "\n",
    "# Table of Content\n",
    "- Imports\n",
    "- Load Data\n",
    "- kaggle_fakenews_df cleaning\n",
    "- kaggle_huff_df cleaning\n",
    "- kaggle_new_york_times_df cleaning\n",
    "- buzzfeed_fakenews_df cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_  = os.path.join('data', 'kaggle_fake_news_train.csv')\n",
    "kaggle_fakenews_df = pd.read_csv(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_  = os.path.join('data', 'kaggle_huff_news_category_v2.json')\n",
    "_ = [json.loads(line) for line in open(_, 'r')]\n",
    "kaggle_huff_df = pd.DataFrame(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = os.path.join('data', 'nytimes_news_articles.txt')\n",
    "with open(_, 'r', encoding=\"utf-8\") as file:\n",
    "    \n",
    "    articles = []\n",
    "    urls = []\n",
    "    index = -1\n",
    "    lines =  file.readlines()  \n",
    "    \n",
    "    for line in lines:    \n",
    "        if line.find('URL:') != -1:\n",
    "            index += 1\n",
    "            urls.append(line.split()[1])\n",
    "            articles.append('')\n",
    "        elif line != '':\n",
    "            articles[index] = articles[index] + line  + ' '\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "kaggle_new_york_times_df = pd.DataFrame({'total': articles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_  = os.path.join('data', 'buzzfeed_2018_fake_news.csv')\n",
    "buzzfeed_fakenews_df = pd.read_csv(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle_fakenews_df cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_fakenews_clean_df = kaggle_fakenews_df.copy()\n",
    "\n",
    "#Dropping the id columns\n",
    "kaggle_fakenews_clean_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Filling remainind columns with nan values with empty strings\n",
    "kaggle_fakenews_clean_df.fillna(' ', inplace=True)\n",
    "\n",
    "# Saving the clean data frame\n",
    "# _  = os.path.join('data', 'clean_kaggle_fakenews_train_df.pkl').replace(f'\\\\''', '/')\n",
    "# kaggle_fakenews_clean_df.to_pickle(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle_huff_df cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the clean data frame\n",
    "# _  = os.path.join('data', 'clean_huff_df.pkl').replace(f'\\\\''', '/')\n",
    "# kaggle_huff_df.to_pickle(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle_new_york_times_df cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _  = os.path.join('data', 'clean_buzzfeed_fakenews_df.pkl').replace(f'\\\\''', '/')\n",
    "# kaggle_new_york_times_df.to_pickle(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# buzzfeed_fakenews_df cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "buzzfeed_fakenews_clean_df = buzzfeed_fakenews_df.copy()\n",
    "\n",
    "buzzfeed_fakenews_clean_df.drop(columns=['source'], axis=1, inplace=True)\n",
    "\n",
    "buzzfeed_fakenews_clean_df.fillna(' ', inplace=True)\n",
    "\n",
    "# _  = os.path.join('data', 'clean_buzzfeed_fakenews_df.pkl').replace(f'\\\\''', '/')\n",
    "# buzz_feed_clean_df.to_pickle(\"data/clean_buzzfeed_fakenews.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
