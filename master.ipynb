{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Since the beginning of news there has always been fake news tricking the unsuspecting into believeing lies. With the concept of fake news populaized by Donald Trump I aimed to solve world problems with ultimate goal to create model that can classify rather a article is fake or real. I use NLP processes to to accomplish this mission.\n",
    "\n",
    "\n",
    "<img src=\"image/MIT-Fake-News.jpg\">\n",
    "\n",
    "\n",
    "\n",
    "# Table of content\n",
    "\n",
    "- Hyperlinks\n",
    "- Imports\n",
    "- Load Data\n",
    "- Split Data\n",
    "- Vectorizing\n",
    "- Grid Search/ Hyperparameter Tuning\n",
    "- Saving Best Grid Search\n",
    "- All Data with Best Estimator/Hyperparameters\n",
    "- Saving Best Model\n",
    "- Best Estimator Metrics\n",
    "- Final Model Metrics\n",
    "\n",
    "\n",
    "\n",
    "- \"\"\"File Name Format <Website>_<article_name_Camelcase>_<what it is>.<file_type>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperlinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Initial data set from kaggle](https://www.kaggle.com/c/fake-news/data)\n",
    "- [Additional Huffinton Articles](https://www.kaggle.com/rmisra/news-category-dataset)\n",
    "- [Additional New York Times Articles](https://www.kaggle.com/nzalake52/new-york-times-articles)\n",
    "- [Additional sources of fake news from buzzfeed](https://www.buzzfeednews.com/article/craigsilverman/facebook-fake-news-hits-2018)\n",
    "- [Reference Material](https://www.kaggle.com/plarmuseau/minimalistic-logistic-ngram-tfidf-lb-0-975)\n",
    "- [List of satire sites](https://libguides.library.kent.edu/c.php?g=278400&p=1854632)\n",
    "- [Media bias chart](https://www.adfontesmedia.com/interactive-media-bias-chart/?v=402f03a963ba)\n",
    "- [List of reliable sites from Forbes](https://www.forbes.com/sites/berlinschoolofcreativeleadership/2017/02/01/10-journalism-brands-where-you-will-find-real-facts-rather-than-alternative-facts/#82973b6e9b5a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import boto3.session\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.base import BaseEstimator\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = os.path.join('data', 'prepared_data_frames_3.zip') \n",
    "with ZipFile(_, 'r') as zip: \n",
    "    zip.extractall('data')\n",
    "\n",
    "\n",
    "_  = os.path.join('data', 'prep_final_df.pkl')\n",
    "_ = open(_, 'rb')\n",
    "_ = pickle.load(_)\n",
    "final_df = _\n",
    "\n",
    "# [AWS SAGE MAKER CODE]\n",
    "# Get the final Data Frame\n",
    "# cred = boto3.Session().get_credentials()\n",
    "# ACCESS_KEY = cred.access_key\n",
    "# SECRET_KEY = cred.secret_key\n",
    "# SESSION_TOKEN = cred.token  ## optional\n",
    "\n",
    "# s3client = boto3.client('s3', \n",
    "#                         aws_access_key_id = ACCESS_KEY, \n",
    "#                         aws_secret_access_key = SECRET_KEY, \n",
    "#                         aws_session_token = SESSION_TOKEN\n",
    "#                        )\n",
    "\n",
    "# bucket='<.....>'\n",
    "# data_key = '<.....>'\n",
    "# data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "# response = s3client.get_object(Bucket=bucket, Key=data_key)\n",
    "\n",
    "# body = response['Body'].read()\n",
    "# final_df = pickle.loads(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 374.308123799546\n",
      "Percentage of columns containing 0: 0.9988211398955031\n"
     ]
    }
   ],
   "source": [
    "X = final_df['total']\n",
    "y = final_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 374.8314962348576\n",
      "Percentage of columns containing 0: 0.9986589548875883\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train)\n",
    "tf_idf_data_test = vectorizer.transform(X_test)\n",
    "\n",
    "non_zero_cols = tf_idf_data_train.nnz / float(tf_idf_data_train.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(tf_idf_data_train.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search/ Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([('clf', DummyEstimator())]) # Placeholder Estimator\n",
    "\n",
    "# Candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'clf': [LogisticRegression()], # Actual Estimator\n",
    "                 'clf__penalty': ['l1', 'l2'],\n",
    "                 'clf__C': np.logspace(0, 4, 10),\n",
    "                 'clf__max_iter': [100, 200, 300]},\n",
    "                \n",
    "                {'clf':[MultinomialNB()], # Actual Estimator\n",
    "                'clf__alpha': [1e-2, 1e-3, 1.0]}, #Parameters\n",
    "                \n",
    "                {'clf': [RandomForestClassifier()],\n",
    "                 'clf__n_estimators' : [50, 100, 200],\n",
    "                 'clf__max_depth' : [None, 40, 100]},             \n",
    "               ]\n",
    "\n",
    "\n",
    "# Create grid search \n",
    "gs = GridSearchCV(pipe, search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Best Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'semi_final_model.pkl'\n",
    "\n",
    "#Save model\n",
    "with open(model_file_name, 'wb') as out:\n",
    "    pickle.dump(gs.best_estimator_, out)\n",
    "\n",
    "#Read Model\n",
    "#with open(model_file_name , 'rb') as inp:\n",
    "#    clf = pickle.load(inp)\n",
    "\n",
    "#[AWS SAGE MAKER CODE] Upload to s3\n",
    "#boto3.Session().resource('<Value>').Bucket('<Value>').Object('<Value>').upload_file(model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data with Best Estimator/Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tf_idf_data = vectorizer.fit_transform(X)\n",
    "\n",
    "lr = LogisticRegression(C=59.94842503189409, \n",
    "                   class_weight=None, \n",
    "                   dual=False,\n",
    "                   fit_intercept=True, \n",
    "                   intercept_scaling=1, \n",
    "                   max_iter=100,\n",
    "                   multi_class='warn', \n",
    "                   n_jobs=None, \n",
    "                   penalty='l2', \n",
    "                   random_state=None,\n",
    "                   solver='warn', \n",
    "                   tol=0.0001, \n",
    "                   verbose=0, \n",
    "                   warm_start=False)\n",
    "\n",
    "lr.fit(tf_idf_data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurent\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Laurent\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model_file_name = 'final_model.pkl'\n",
    "\n",
    "#Save model\n",
    "#with open(model_file_name, 'wb') as out:\n",
    "#    pickle.dump(lr, out)\n",
    "\n",
    "#Read Model\n",
    "with open(model_file_name , 'rb') as inp:\n",
    "    clf = pickle.load(inp)\n",
    "\n",
    "#[AWS SAGE MAKER CODE] Upload to s3\n",
    "#boto3.Session().resource('<Value>').Bucket('<Value>').Object('<Value>').upload_file(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8586967 , -0.59820096, -0.10114524, ..., -0.07457475,\n",
       "        -0.07457475, -0.07457475]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Estimator Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = gs.best_estimator_.predict(tf_idf_data_train)\n",
    "y_pred_test = gs.best_estimator_.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_train, y_pred_train, target_names=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, y_pred_test, target_names=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(tf_idf_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y, y_pred, target_names=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df['total']\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_data_train = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl', 'wb') as out:\n",
    "    pickle.dump(vectorizer, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurent\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Laurent\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Read Model\n",
    "with open('final_model.pkl' , 'rb') as inp:\n",
    "    clf = pickle.load(inp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
